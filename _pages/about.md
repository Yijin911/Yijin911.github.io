---
layout: about
title: about
permalink: /
subtitle:

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    <p><a href='#'>Email</a>. yni64 AT gatech.edu</p>

selected_papers: false # includes a list of papers marked as "selected={true}"
social: false # includes social icons at the bottom of the page

announcements:
  enabled: true # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: false
  scrollable: true # adds a vertical scroll bar if there are more than 3 new post items
  limit: 3 # leave blank to include all the blog posts
---

I am a Ph.D. candidate under the Statistics track of the [Industrial and Systems Engineering school](https://www.isye.gatech.edu/) at Georgia Institute of Technology, fortunate to be advised by [Prof. Xiaoming Huo](https://www.isye.gatech.edu/users/xiaoming-huo).

Prior to Georgia Tech, I received my Bachelorâ€™s degree in Statistics in 2020 from the [University of Science and Technology of China](https://en.ustc.edu.cn/) (USTC), advised by [Prof. Canhong Wen](https://scholar.google.com/citations?user=9oZ58-0AAAAJ&hl=en).

I am broadly in the utilization of statistical tools in the exploration of methodologies. Specifically, my research topics include: 
- **Nonlinear uniform concentration inequality**, regarding theoretical boundaries for optimization problems;
- **Kernel-based statistics**, including *Maximum Mean Discrepancy* (MMD), *Hilbert-Schmidt Independence Criterion* (HSIC), *Energy Distance* (ED), and *distance Covariance* (dCov);
- **Dimension reduction and variable selection**, serving as a preprocessing step for high dimensional statistics;
- **Fairness representation learning**, exploring available metrics to achieve fairness for a wide range of downstream tasks;
- **Preference learning for LLM fine-tuning**, including *Direct Prefernece Optimization* (DPO) and *Reinforcement Learning from Human Feedback* (RLHF).
